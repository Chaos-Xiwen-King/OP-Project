            +---------------------------------+
            |        	  CS 140              |
            |       PROJECT 1: THREADS        |
            |         DESIGN DOCUMENT         |
            +---------------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

康曦文 <18373607@buaa.edu.cn>
郭凌宇 <1641510809@qq.com>
陈宇畅 <494261741@qq.com>
赵致远 <512063422@qq.com>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

* 参考他人的实现方式
https://www.cnblogs.com/laiy/p/pintos_project1_thread.html
* 忙碌等待
https://baike.baidu.com/item/忙碌等待/16256157?fr=aladdin


                 ALARM CLOCK
                 ===========


---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* blocked_ticks 是线程结构体 struct thread 里的一个新的成员变量。它标志着这个线程还需要被阻塞的时间。 */
/* belem 是线程结构体 struct thread 里的一个新的成员变量。它用于形成因调用timer_sleep()而阻塞的线程链表。 */
 struct thread
 {
   int64_t blocked_ticks;              /* 因调用timer_sleep()而阻塞的线程，其结束阻塞的绝对时间 */
   struct list_elem belem;              /* 因调用timer_sleep()阻塞的线程链表 */
 };

/* 
  each_blocked_time_check() 是在thread.h中声明的一个新的成员函数，并在 thread.c 中实现。
  它以系统运行时间 ticks 作为参数，检查阻塞线程链表的 ticks_blocked 成员，并判断是否应当将这个线程重新放回空闲队列中。
*/
 void each_blocked_time_check (void *aux);

/*
  thread_block_time_priority_cmp() 是在thread.h中声明的一个新的成员函数，并在thread.c中实现。
  它作为比较函数，规定了阻塞线程插入链表时按照 blocked_ticks 参数从小到大的顺序。
*/
 bool thread_block_time_priority_cmp (const struct list_elem *a, const struct list_elem *b);

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

timer_sleep(int64_t tick) 会使当前线程进入阻塞状态，直到 ticks 次系统时间中断之后重新使进程进入等待状态。timer_sleep() 被调用时，CPU应当处于可以被中断的状态。
timer_sleep(int64_t tick) 将当前线程结构体里的 blocked_ticks 的值修改为 tick + ticks，并将当前线程放入阻塞队列中，然后阻塞当前线程。
在时间中断函数中添加对于所有线程的 blocked_ticks 值的判断，使得每次时间中断函数 time_interrupt() 发生时，如果 blocked_ticks 成员等于当前的 ticks，就把该线程放入空闲队列中，等待 schedule() 函数的调度，并从阻塞队列中删除该线程。

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

建立了一个新的阻塞链表，其中包括所有因为调用 timer_sleep() 而进入阻塞状态的线程。
在时间中断中遍历阻塞列表线程的 blocked_ticks 成员，碰到第一个大于 ticks 的线程时跳出，并将之前的线程放入等待队列中，并在阻塞队列中删除。
（这些线程的 blocked_ticks 应当等于 ticks）

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

由于 timer_sleep() 函数中涉及到计时中断函数 timer_interrupt()，因此在调用 timer_sleep() 之前都应该保证当前的中断应当被允许，代码中使用断言来保证这一点。
中断会在 timer_sleep() 函数开始时被禁止，这样在调用线程调度函数 schedule() 进行上下文切换的时候，其他线程对于 timer_sleep() 会停在对于中断断言的地方。
当前线程被挂起、寄存器的值被存储在线程栈上，并且下一个调度的线程状态已经被恢复之后，中断重新被允许，其他线程可以调用 timer_sleep()。

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

理由同A4，此时计时中断被禁止了。

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

该算法相比于原算法有着显而易见的优点。原算法不断地当前线程放入空闲队列当中，无意义的调用 schedule()，将长时间的占用CPU资源(特别是当前空闲的线程较少时)。而当前算法将线程设置成阻塞状态，在每次时间中断函数中修改并检查线程是否应当被唤醒，CPU将不必进行没有意义的上下文切换，schedule() 的调度将只会涉及处于空闲队列中的线程，而阻塞线程并不在其中。


             PRIORITY SCHEDULING
             ===================


---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

thread 数据结构加入以下成员:
   /* 保存在未接受捐赠之前线程的优先级*/
   int init_priority;                 
   /* 保存线程所持有的所有锁 */
   struct list locks;
   /* 当前线程正在等待的锁 */            
   struct lock *lock_waiting;      


lock 数据结构加入以下成员:
   /*持有这个锁的所有线程 */
   struct list_elem elem;
   /*所有持有该锁线程中的最大优先级*/
   int max_priority;

>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)

为了解决这个问题，我们在thread数据结构中加入init_priority, locks, lock_waiting, 
在lock数据结构中加入elem, max_priority成员来帮助跟踪优先级贡献。

每当一个锁被一个线程所调用时，该线程便插入elem队列中；同样的，每当一个线程释放一个锁，
该线程就从elem队列中移出。

对于每一次优先级捐赠，每当一个锁被调用时，该锁的持有者会进行优先级的检查。如果
持有者的优先级比其他持有该锁线程的优先级低，捐赠就会发生。当前线程的优先级会被捐赠为
和所有持有该锁线程中的最大优先级一样。如果当前线程的优先级比其他线程都要高，则
锁的优先级将改变为和当前线程的优先级一样。

如果该线程又被另外一个线程锁住，那么就会产生一个嵌套。即如果一个线程被多个线程
所捐赠时，维持当前优先级为被捐赠的优先级中的最大值。

当一个锁被释放时，这个锁会从当前线程中的locks队列中移出并检查当前线程是否处于被捐赠的
状态。如果当前locks队列为空，能够知道当前线程不处于被捐赠的状态，那么线程的优先级恢复为
被捐赠前的优先级，即init_priority，否则，取出locks中拥有最大优先级的锁进行比较。如果锁的
优先级比当前优先级还来的大，则改变为当前的最大优先级，否则设置为init_priority。其中locks
队列采用了降序排列，即最大优先级的锁放在对头，因此我们能够保证取出的是线程持有锁的最大
优先级。

使用数据结构和上面的算法，优先级捐赠就能够实现。

举一个例子:
A thread, priority 31, has lock lock_1. 
B thread, priority 32, has lock lock_2, and acquire lock_1
C thread, priority 33, acquire lock_2 

Step 1: At the beginning:
=========================
.---------------------------------------------------.
|                Thread A (Beginning)               |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            31 |
| init_priority     |                            31 |
| locks             |  {lock_1 (max_priority = -1)} |
| lock_waiting      |                          NULL |
'-------------------+-------------------------------'
.---------------------------------------------------.
|                Thread B (Beginning)               |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priority     |                            32 |
| locks             |  {lock_2 (max_priority = -1)} |
| lock_waiting      |                          NULL |
'-------------------+-------------------------------'
.---------------------------.
|    Thread C (Beginning)   |
+-------------------+-------+
| member            | value |
+-------------------+-------+
| priority          |    33 |
| init_priority     |    33 |
| locks             |    {} |
| lock_waiting      |  NULL |
'-------------------+-------'
==================================================================

Step 2: B acquires lock_1:
==========================
.---------------------------------------------------.
|              Thread A (B acquires L1)             |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priority     |                            31 |
| locks             | {lock_1 (priority_lock = 32)} |
| lock_waiting      |                          NULL |
'-------------------+-------------------------------'
.---------------------------------------------------.
|              Thread B (B acquires L1)             |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priority     |                            32 |
| locks             | {lock_2 (priority_lock = -1)} |
| lock_waiting      |                        &lock1 |
'-------------------+-------------------------------'
.---------------------------.
|  Thread C (B acquires L1) |
+-------------------+-------+
| member            | value |
+-------------------+-------+
| priority          |    33 |
| init_priority     |    33 |
| locks             |    {} |
| lock_waiting      |  NULL |
'-------------------+-------'
==================================================================

STEP 3-1: C acquires lock_2:
============================
.---------------------------------------------------.
|          Thread B (C acquires L2, Step 1)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            33 |
| init_priority     |                            32 |
| locks             | {lock_2 (priority_lock = 33)} |
| lock_waiting      |                        &lock1 |
'-------------------+-------------------------------'
.----------------------------------.
| Thread C (C acquires L2, Step 1) |
+----------------------+-----------+
| member               | value     |
+----------------------+-----------+
| priority             |        33 |
| init_priority        |        33 |
| locks                |        {} |
| lock_waiting         |   &lock_2 |
'----------------------+-----------'
.---------------------------------------------------.
|          Thread A (C acquires L2, Step 1)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priorityl    |                            31 |
| locks             | {lock_1 (priority_lock = 32)} |
| lock_waiting      |                          NULL |
'-------------------+-------------------------------'
==================================================================

STEP 3-2: C acquires lock_2:
============================
.---------------------------------------------------.
|          Thread B (C acquires L2, Step 2)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            33 |
| init_priority     |                            32 |
| locks             | {lock_2 (priority_lock = 33)} |
| lock_waiting      |                        &lock1 |
'-------------------+-------------------------------'
.----------------------------------.
| Thread C (C acquires L2, Step 2) |
+----------------------+-----------+
| member               | value     |
+----------------------+-----------+
| priority             |        33 |
| init_priority        |        33 |
| locks                |        {} |
| lock_waiting         |   &lock_2 |
'----------------------+-----------'
.---------------------------------------------------.
|          Thread A (C acquires L2, Step 2)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            33 |
| init_priority     |                            31 |
| locks             | {lock_1 (priority_lock = 32)} |
| lock_waiting      |                          NULL |
'-------------------+-------------------------------'
==================================================================

STEP 4: A releases lock_1:
==========================
.-------------------------------.
| Thread A (A releases lock_1)) |
+---------------------+---------+
| member              | value   |
+---------------------+---------+
| priority            |      31 |
| init_priority       |      31 |
| locks               |      {} |
| lock_waiting        |    NULL |
'---------------------+---------'
.----------------------------------------------------.
|            Thread B (A releases lock_1)            |
+-------------------+--------------------------------+
| member            | value                          |
+-------------------+--------------------------------+
| priority          |                             33 |
| init_priority     |                             32 |
| locks             | {&lock_2 (priority_lock = 33), |
|                   |  &lock_1 (priority_lock = 32)} |
| lock_waiting      |                           NULL |
'-------------------+--------------------------------'
.------------------------------.
| Thread C (A releases lock_1) |
+--------------------+---------+
| member             | value   |
+--------------------+---------+
| priority           |      33 |
| init_priority      |      33 |
| locks              |      {} |
| lock_waiting       | &lock_2 |
'--------------------+---------'
==================================================================

STEP 5: B releases lock_2:
==========================
.-------------------------------.
| Thread A (B releases lock_2)) |
+---------------------+---------+
| member              | value   |
+---------------------+---------+
| priority            |      31 |
| init_priority       |      31 |
| locks               |      {} |
| lock_waiting        |    NULL |
'---------------------+---------'
.----------------------------------------------------.
|            Thread B (B releases lock_2)            |
+-------------------+--------------------------------+
| member            | value                          |
+-------------------+--------------------------------+
| priority          |                             32 |
| init_priority     |                             32 |
| locks             | {&lock_1 (priority_lock = 32)} |
| lock_waiting      |                           NULL |
'-------------------+--------------------------------'
.----------------------------------------------------.
|            Thread C (B releases lock_2)            |
+-------------------+--------------------------------+
| member            | value                          |
+-------------------+--------------------------------+
| priority          |                             33 |
| init_priority     |                             33 |
| locks             | {&lock_2 (priority_lock = 33)} |
| lock_waiting      |                           NULL |
'-------------------+--------------------------------'
==================================================================

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?

将等待队列实现为优先队列，按照线程优先级的大小降序排列。

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?

A: 步骤:
   1. 屏蔽中断。
   2. 捐献
     2.1 如果锁的持有者为空
     2.1.1  执行sema_down函数: 如果sema->value的值为0，则将所有请求这个锁的线程放入
	等待队列中，直到sema->value不为0
     2.1.2  将现在的进程设置为锁的持有者
     2.2 比较锁的持有者与当前线程的优先级
     2.2.1  锁持有者的优先级大于当前线程的优先级
     2.2.1.1  当前线程等待锁的释放         
     2.2.1.2  将当前线程设置为锁的持有者
     2.2.2  锁持有者的优先级大于当前线程的优先级
     2.2.2.1  [捐赠] 将锁持有者的优先级设置为当前线程的优先级
     2.2.2.2  等待锁的释放
     2.2.2.3  当前线程成为锁的持有者
   3. 将中断设置为禁用之前的状态。

如果锁的持有者被另一个锁阻塞，就用thread数据结构中的lock_waiting找到那个锁，并
重复上述的操作，直到这个线程的lock_waiting为空，这样，所有的锁持有者就拥有了同样的
优先级。

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.

A: 步骤:
   1. 保证这个线程是当前锁的持有者，如果不是，输出错误。
   2. 屏蔽中断。
   3. 将锁的持有者设置为空
   4. 执行sema_up函数: 如果当前等待队列不为空，则将队列按优先级排序，并取出
		队头。让sema->value加1，这代表当前锁可以被其他队列所
		获取
   5. 设置锁持有者的优先级
     5.1 没有发生捐赠
           将锁持有者的优先级设置为初始优先级
     5.2 发生捐赠
     5.2.1  锁持有者仅仅持有这一个锁
     5.2.1.1  将锁持有者的优先级设置为初始优先级
     5.2.2  嵌套捐赠
     5.2.2.1  将锁持有者的优先级设置为locks队列中的最大优先级

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

在优先级捐赠的过程中，锁持有者的优先级可能被它的捐赠者设置，同时，这个线程本身也想要
改变优先级。这两个过程会发生冲突，根据执行顺序的不同，线程当前的优先级会有不同的结果。

在设置优先级的过程中，我们采用了和设置时钟时同样的方法来屏蔽中断。不能够使用锁来阻止这样
一个过程。因为我们没有设置方法让锁持有者和捐赠者共享同一个锁。
---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

在设计方案的时候，我们采用的是TDD方式，在分析了所有测试代码的意图之后，我们决定设计上述的数据结构，
并依照数据结构确定了解决方案。

thread 结构体必须要记录自身原本的优先级和被捐赠的优先级，刚开始我们打算记录下所有捐赠给该线程的优先级，维护一个存储优先级的数组，
但这种方法不切实际，无法得知优先级的捐赠者，进而发现只需要记录自身原本的优先级和当前的优先级即可，当优先级改变时只需要借助函数方法及时更新即可。
除此之外，thread 结构体还要记录自身等待的锁以及所有自身持有的锁。

lock 结构体需要记录所有等待在这个锁上的线程。原本在设计时，我们没有打算在该结构体中记录锁的最大优先级。
然而，在多个线程准备获取锁的时候，事先记录下等待锁的线程中的最大优先级能够避免遍历一遍等待该锁的线程队列以判断是否要捐赠优先级，故而添加了该数据结构。


              ADVANCED SCHEDULER
              ==================


---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* 给每个线程一个nice参数和一个recent_cpu参数，供后续重新计算线程的优先级以实现mlfqs。*/
struct thread中添加
{
	int nice;               /* Nice parameter. */
	fixed_t recent_cpu;        /* CPU time occupied by the thread. */
}

/* 在thread.c中添加变量,用于计算优先级的参数*/
fixed_t load_avg;

/* 在fixed_point.h中定义*/
typedef int fixed_t;

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

由于源代码中给出
#define TIMER_FREQ 100
这里若以TIMER_TREQ=100为例计算，recent_cpu只在最开始计算一次，后续不需要考虑recent_cpu和load_avg通过公式的更新。并且我们这里假设这64个队列均采取FCFS顺序来服务,3个线程在20个时钟周期内都不会结束。


timer  recent_cpu    priority    thread
ticks  A   B   C     A   B   C   to run
-----  --  --  --    --  --  --  ------
 0     0   1   2     63  61  59   A
 4     4   1   2     62  61  59   A
 8     8   1   2     61  61  59   B
12     8   5   2     61  60  59   A
16    12   5   2     60  60  59   B
20    12   9   2     60  59  59   A
24    16   9   2     59  59  59   C
28    16   9   6     59  59  58   B
32    16  13   6     59  58  58   A
36    20  13   6     58  58  58   C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

recent_cpu是不准确的。
可以认为，线程运行时间的一个基本单位是4个时钟周期，因为在线程运行的四个时钟周期中，CPU需要进行调度信息的处理，即recent_cpu和load_avg以及priority的计算，
这就导致一个线程在4个时钟周期中，实际占有CPU的时间是小于4个周期的。
处理方式：粗略认为线程的运行时间为4个时钟周期。

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

如果一个线程实际占有CPU的时间较短，此时，调度信息的处理，即recent_cpu和load_avg以及priority的计算，所占用CPU的时间，就会很大程度上影响此线程的占有CPU
的时间，进而会被降低优先级。
所以如果调度的占用的时间过长，就会导致系统效率的降低。

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

设计中，没有真正实现64个队列，只是维护了一个readylist的优先队列，通过降低占有CPU时间过长的线程的优先级来控制线程的运行顺序。
这样做实现起来更简便，但线程的调度所需的时间为O(n)，若实现64个队列，则线程的调度所需时间仅为O(1)

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

我们在fixed_point.h中定义了一系列的宏来实现浮点数运算。
原因有以下几点：
1、recent_cpu和load_avg的运算需要浮点数运算来实现。
2、比起函数，使用宏定义更加简明。
3、所需功能较为简单，宏定义可以实现。
