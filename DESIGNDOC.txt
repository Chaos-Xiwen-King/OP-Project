            +---------------------------------+
            |        	    CS 140               |
            | PROJECT 1: THREADS  |
            |   DESIGN DOCUMENT   |
            +---------------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

郭凌宇 <1641510809@qq.com>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

blocked_ticks是线程结构体struct thread里的一个新的成员变量。它标志着这个线程还需要被阻塞的时间。
struct thread
{
  int64_t blocked_ticks;              /* Number of ticks thread blocks */
};

blocked_time_check (struct thread *t)是在thread.h中声明的一个新的成员函数，并在thread.c中实现。它检查一个线程的blocked_ticks成员，并判断是否应当将这个线程重新放回空闲队列中。
void blocked_time_check (struct thread *t);

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

timer_sleep(int64_t ticks)会使当前线程进入阻塞状态，直到ticks次系统时间中断之后重新使进程进入等待状态。timer_sleep()被调用时，CPU应当处于可以被中断的状态。
timer_sleep(int64_t ticks)将当前线程结构体里的blocked_ticks的值修改为函数参数ticks，然后阻塞当前线程。在时间中断函数中添加对于所有线程的blocked_ticks值的判断和修改，使得每次时间中断函数time_interrupt()发生时，对所有当前线程的timer_blocked成员进行自减1的操作，如果timer_blocked成员变成了0，就把该线程放入空闲队列中，等待schedule()函数的调度。

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

由于timer_sleep()函数中涉及到时间中断函数timer_interrupt()，因此在调用timer_sleep()之前都应该保证当前的中断应当被允许，代码中使用断言来保证这一点。中断会在timer_sleep()函数开始时被禁止，这样在调用线程调度函数schedule()进行上下文切换的时候，其他线程对于timer_sleep()会停在对于中断断言的地方。当前线程被挂起、寄存器的值被存储在线程栈上，并且下一个调度的线程状态已经被恢复之后，中断重新被允许，其他线程可以调用timer_sleep()。
>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

该算法相比于原算法有着显而易见的优点。原算法不断地当前线程放入空闲队列当中，无意义的调用schedule()，将长时间的占用CPU资源(特别是当前空闲的线程较少时)。而当前算法将线程设置成阻塞状态，在每次时间中断函数中修改并检查线程是否应当被唤醒，CPU将不必进行没有意义的上下文切换，schedule()的调度将只会涉及处于空闲队列中的线程，而阻塞线程并不在其中。
             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----
修改thread数据结构，加入以下数据：
int base_priority
struct list locks
struct lock *lock_waiting
修改lock数据结构，加入以下数据：
struct list_elem elem
int max_priority

>>thread中，base_priority记录的是创建线程开始时的优先级，而priority记录的是目前线程所拥有的优先级。priority可能会随着程序的运行而发生改变，但base_priority是不发生改变的。locks记录的是目前为止该线程拥有的锁，lock_waiting表述的是该线程正在等待的锁。
>>lock数据结构中elem表述的是对于给锁提供优先级的全部线程，max_priority指的是得到这个锁的所有线程中的最高级。


---- ALGORITHMS ----
>>对于等待锁，信号量，condition的队列全部实现为优先队列

锁队列排序函数lock_cmp_priority：
2 bool
3 lock_cmp_priority (const struct list_elem *a, const struct list_elem *b, void *aux UNUSED)
4 {
5   return list_entry (a, struct lock, elem)->max_priority > list_entry (b, struct lock, elem)->max_priority;
6 }

对于实现condition的优先队列，首先修改cond_signal函数：
void
cond_signal (struct condition *cond, struct lock *lock UNUSED)
{
  ASSERT (cond != NULL);
  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (lock_held_by_current_thread (lock));

  if (!list_empty (&cond->waiters))
  {
    list_sort (&cond->waiters, cond_sema_cmp_priority, NULL);
    sema_up (&list_entry (list_pop_front (&cond->waiters), struct semaphore_elem, elem)->semaphore);
  }
}
写出比较函数cond_sema_cmp_priority：
bool
cond_sema_cmp_priority (const struct list_elem *a, const struct list_elem *b, void *aux UNUSED)
{
  struct semaphore_elem *sa = list_entry (a, struct semaphore_elem, elem);
  struct semaphore_elem *sb = list_entry (b, struct semaphore_elem, elem);
  return list_entry(list_front(&sa->semaphore.waiters), struct thread, elem)->priority > list_entry(list_front(&sb->semaphore.waiters), struct thread, elem)->priority;
}

实现信号量的等待队列为优先级队列，修改函数sema_up：
void
sema_up (struct semaphore *sema)
{
  enum intr_level old_level;

  ASSERT (sema != NULL);

  old_level = intr_disable ();
  if (!list_empty (&sema->waiters))
  {
    list_sort (&sema->waiters, thread_cmp_priority, NULL);
    thread_unblock (list_entry (list_pop_front (&sema->waiters), struct thread, elem));
  }

  sema->value++;
  thread_yield ();
  intr_set_level (old_level);
}
修改sema_down：
void
sema_down (struct semaphore *sema)
{
  enum intr_level old_level;

  ASSERT (sema != NULL);
  ASSERT (!intr_context ());

  old_level = intr_disable ();
  while (sema->value == 0)
    {
      list_insert_ordered (&sema->waiters, &thread_current ()->elem, thread_cmp_priority, NULL);
      thread_block ();
    }
  sema->value--;
  intr_set_level (old_level);
}

>>修改lock_acquire函数：
void
lock_acquire (struct lock *lock)
{
  struct thread *current_thread = thread_current ();
  struct lock *l;
  enum intr_level old_level;

  ASSERT (lock != NULL);
  ASSERT (!intr_context ());
  ASSERT (!lock_held_by_current_thread (lock));

  if (lock->holder != NULL && !thread_mlfqs)
  {
    current_thread->lock_waiting = lock;
    l = lock;
    while (l && current_thread->priority > l->max_priority)
    {
      l->max_priority = current_thread->priority;
      thread_donate_priority (l->holder);
      l = l->holder->lock_waiting;
    }
  }

  sema_down (&lock->semaphore);

  old_level = intr_disable ();

  current_thread = thread_current ();
  if (!thread_mlfqs)
  {
    current_thread->lock_waiting = NULL;
    lock->max_priority = current_thread->priority;
    thread_hold_the_lock (lock);
  }
  lock->holder = current_thread;

  intr_set_level (old_level);
}
当调用lock_acquire函数时，当前线程等待的锁设置为该锁，如果拥有这个锁的线程优先级比自己低就提高锁的优先级，并且如果这个锁还被其他锁锁着，将会递归捐赠优先级，直到该线程放掉这个锁，恢复到捐赠前的优先级，即while循环里的内容。之后就是让该线程拥有该锁。
函数thread_donate_priority的作用是将线程优先级捐赠给锁：
/* Donate current priority to thread t. */
void
thread_donate_priority (struct thread *t)
{
  enum intr_level old_level = intr_disable ();
  thread_update_priority (t);

  if (t->status == THREAD_READY)
  {
    list_remove (&t->elem);
    list_insert_ordered (&ready_list, &t->elem, thread_cmp_priority, NULL);
  }
  intr_set_level (old_level);
}
其中的函数thread_update_priority的作用是更新线程的优先级：
void
thread_update_priority (struct thread *t)
{
  enum intr_level old_level = intr_disable ();
  int max_priority = t->base_priority;
  int lock_priority;

  if (!list_empty (&t->locks))
  {
    list_sort (&t->locks, lock_cmp_priority, NULL);
    lock_priority = list_entry (list_front (&t->locks), struct lock, elem)->max_priority;
    if (lock_priority > max_priority)
      max_priority = lock_priority;
  }

  t->priority = max_priority;
  intr_set_level (old_level);
}
当这个线程处于被捐赠的状态时，对lock_priority进行设置，如果lock_priority大于目前的优先级，则priority设置为lock_priority，否则，线程优先级为本身的优先级。
thread_hold_the_lock函数作用是插入当前线程进入优先队列，并设置当前线程的优先级，即让线程拥有该锁：
void
thread_hold_the_lock(struct lock *lock)
{
  enum intr_level old_level = intr_disable ();
  list_insert_ordered (&thread_current ()->locks, &lock->elem, lock_cmp_priority, NULL);

  if (lock->max_priority > thread_current ()->priority)
  {
    thread_current ()->priority = lock->max_priority;
    thread_yield ();
  }

  intr_set_level (old_level);
}

>>在lock_release函数中加入语句：
if (!thread_mlfqs)
  thread_remove_lock(lock);
其中thread_remove_lock函数如下：
void
thread_remove_lock (struct lock *lock)
{
  enum intr_level old_level = intr_disable ();
  list_remove (&lock->elem);
  thread_update_priority (thread_current ());
  intr_set_level (old_level);
}
函数将线程从拥有该锁的线程队列中移出，并更新当前线程的优先级。
当释放锁的时候如果对一个锁的优先级有所改变应考虑被捐赠的优先级和当前优先级。


---- SYNCHRONIZATION ----

>>修改thread_set_priority函数：
void
thread_set_priority (int new_priority)
{
  if (thread_mlfqs)
    return;

  enum intr_level old_level = intr_disable ();

  struct thread *current_thread = thread_current ();
  int old_priority = current_thread->priority;
  current_thread->base_priority = new_priority;

  if (list_empty (&current_thread->locks) || new_priority > old_priority)
  {
    current_thread->priority = new_priority;
    thread_yield ();
  }

  intr_set_level (old_level);
}
对于原先的函数，可能会出现这种情况：当前线程创建一个优先级高的线程。因为新线程优先级高，便切换到新的线程，新线程执行到changing_thread，又切换到原来的线程，原来线程执行到changing_thread也切换，如此往复。
修改方法为在设置一个线程优先级要礼记重新考虑所有线程的执行顺序，重新安排执行顺序。


---- RATIONALE ----
>>选择这样的方法是因为通过逻辑上的分析，这样做能够更有效率。通过添加数据结构成员和改变方法，能够让程序运行的更有逻辑性。

ADVANCED SCHEDULER
==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread中添加
{
	int nice;               /* Nice parameter. */
	fixed_t recent_cpu;        /* CPU time occupied by the thread. */
}
根据文档内容，给每个线程一个nice参数和一个recent_cpu参数，供后续重新计算线程的优先级以实现mlfqs。

在thread.c中添加变量
fixed_t load_avg;
同样是用于计算优先级的参数。

在fixed_point.h中定义
typedef int fixed_t;


---- ALGORITHMS ----
MLFQS的主要目的是：根据不同CPU区间的特点以区分进程，将占用过多CPU时间的线程的优先级降低，以保证I/O约束和交互线程等占用CPU时间较少的线程的优先级更高，从而减少系统的平均响应时间。

这里我们的BSD Scheduler的主要思路为：每过一定的时间，重新计算线程的优先级，以降低占用过多CPU时间的线程的优先级。具体做法为

1、每过4个ticks( tick % 4 == 0 )，重新计算优先级，公式为
priority  =  max_priority  - (recent_cpu/4) - nice*2
2、每过100个ticks(tick % timer_freq == 0),通过以下公式更新recent_cpu和load_avg
recent_cpu  = recent_cpu * (2*load_avg)/(2*load_avg+1) + nice
load_avg = load_avg*59/60 + 1/60 *  ready_thread
3、每个时钟周期，正在运行的线程的recent_cpu增加1

thread.c中添加以下三个函数：

void
thread_recent_cpu_increase (void)
{
  ASSERT (thread_mlfqs);
  ASSERT (intr_context ());

  struct thread *cur = thread_current ();
  if (cur == idle_thread)
    return;
  cur->recent_cpu = FP_ADD_MIX (cur->recent_cpu, 1);
}

/* refresh load_avg and recent_cpu for all threads. */
void
thread_load_avg_recent_cpu_update (void)
{
  ASSERT (thread_mlfqs);
  ASSERT (intr_context ());

  size_t ready_thread_cnt = list_size (&ready_list);
  if (thread_current () != idle_thread)
    ready_thread_cnt++;

  load_avg = FP_ADD (FP_DIV_MIX (FP_MULT_MIX (load_avg, 59), 60), FP_DIV_MIX (FP_CONST (ready_thread_cnt), 60));

  struct thread *t;
  struct list_elem *e = list_begin (&all_list);

  for (; e != list_end (&all_list); e = list_next(e))
  {
    t = list_entry (e, struct thread, allelem);
    if (t != idle_thread)
    {
      t->recent_cpu = FP_ADD_MIX (FP_MULT (FP_DIV (FP_MULT_MIX (load_avg, 2), FP_ADD_MIX (FP_MULT_MIX (load_avg, 2), 1)), t->recent_cpu), t->nice);
      thread_mlfqs_priority_update (t);
    }
  }
}

/*  */
void
thread_mlfqs_priority_update (struct thread *t)
{
  if (t == idle_thread)
    return;

  ASSERT (thread_mlfqs);
  ASSERT (t != idle_thread);

  t->priority = FP_INT_PART (FP_SUB_MIX (FP_SUB (FP_CONST (PRI_MAX), FP_DIV_MIX (t->recent_cpu, 4)), 2 * t->nice));
  t->priority = t->priority < PRI_MIN ? PRI_MIN : t->priority;
  t->priority = t->priority > PRI_MAX ? PRI_MAX : t->priority;
}

timer.c中的timer_interrupt中加入以下内容
if (thread_mlfqs)
  {
    thread_recent_cpu_increase ();
    if (ticks % TIMER_FREQ == 0)
      thread_load_avg_recent_cpu_update ();
    else if (ticks % 4 == 0)
      thread_mlfqs_priority_update (thread_current ());
  }

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

由于源代码中给出
#define TIMER_FREQ 100
这里若以TIMER_TREQ=100为例计算，recent_cpu只在最开始计算一次，后续不需要考虑recent_cpu和load_avg通过公式的更新。并且我们这里假设这64个队列均采取FCFS顺序来服务,3个线程在20个时钟周期内都不会结束。


timer  recent_cpu    priority   thread
ticks   A   B   C        A   B   C   to run
-----   --  --  --         --  --  --   ------
 0       0   1   2          63  61 59	 A
 4       4   1   2          62  61 59    A
 8       8   1   2          61  61 59    B
12      8   5   2          61  60 59    A
16     12  5   2          60  60 59    B
20     12  9   2          60  59 59    A
24     16  9   2          59  59  59   C
28     16  9   6          59  59 58    B
32     16  13  6         59  58 58    A
36     20  13  6         58  58 58    C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

recent_cpu是不准确的。
可以认为，线程运行时间的一个基本单位是4个时钟周期，因为在线程运行的四个时钟周期中，CPU需要进行调度信息的处理，即recent_cpu和load_avg以及priority的计算，
这就导致一个线程在4个时钟周期中，实际占有CPU的时间是小于4个周期的。
处理方式：粗略认为线程的运行时间为4个时钟周期。

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

如果一个线程实际占有CPU的时间较短，此时，调度信息的处理，即recent_cpu和load_avg以及priority的计算，所占用CPU的时间，就会很大程度上影响此线程的占有CPU
的时间，进而会被降低优先级。
所以如果调度的占用的时间过长，就会导致系统效率的降低。

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

设计中，没有真正实现64个队列，只是维护了一个readylist的优先队列，通过降低占有CPU时间过长的线程的优先级来控制线程的运行顺序。
这样做实现起来更简便，但线程的调度所需的时间为O(n)，若实现64个队列，则线程的调度所需时间仅为O(1)

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

我们在fixed_point.h中定义了一系列的宏来实现浮点数运算。
原因有以下几点：
1、recent_cpu和load_avg的运算需要浮点数运算来实现。
2、比起函数，使用宏定义更加简明。
3、所需功能较为简单，宏定义可以实现。

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
