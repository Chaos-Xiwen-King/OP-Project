            +---------------------------------+
            |        	    CS 140            |
            | PROJECT 1: THREADS              |
            |   DESIGN DOCUMENT               |
            +---------------------------------+

---- GROUP ----

>> Fill in the names and email addresses of your group members.

康曦文 <18373607@buaa.edu.cn>
郭凌宇 <1641510809@qq.com>
陈宇畅 <494261741@qq.com>
赵致远 <512063422@qq.com>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.
* 参考他人的实现方式
https://www.cnblogs.com/laiy/p/pintos_project1_thread.html
* 忙碌等待
https://baike.baidu.com/item/忙碌等待/16256157?fr=aladdin

                 ALARM CLOCK
                 ===========

---- DATA STRUCTURES ----

>> A1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

/* blocked_ticks 是线程结构体 struct thread 里的一个新的成员变量。它标志着这个线程还需要被阻塞的时间。 */
struct thread
{
  int64_t blocked_ticks;              /* Number of ticks thread blocks */
};

/* 
  blocked_time_check (struct thread *t) 是在thread.h中声明的一个新的成员函数，并在 thread.c 中实现。它检查一个线程的 ticks_blocked 成员，并判断是否应当将这个线程重新放回空闲队列中。 
*/
void blocked_time_check (struct thread *t);

---- ALGORITHMS ----

>> A2: Briefly describe what happens in a call to timer_sleep(),
>> including the effects of the timer interrupt handler.

timer_sleep(int64_t ticks) 会使当前线程进入阻塞状态，直到 ticks 次系统时间中断之后重新使进程进入等待状态。timer_sleep() 被调用时，CPU应当处于可以被中断的状态。
timer_sleep(int64_t ticks) 将当前线程结构体里的 ticks_blocked 的值修改为函数参数 ticks，然后阻塞当前线程。在时间中断函数中添加对于所有线程的 ticks_blocked 值的判断和修改，使得每次时间中断函数 time_interrupt() 发生时，对所有当前线程的 timer_blocked 成员进行自减1的操作，如果 timer_blocked 成员变成了0，就把该线程放入空闲队列中，等待 schedule() 函数的调度。

>> A3: What steps are taken to minimize the amount of time spent in
>> the timer interrupt handler?

---- SYNCHRONIZATION ----

>> A4: How are race conditions avoided when multiple threads call
>> timer_sleep() simultaneously?

由于 timer_sleep() 函数中涉及到计时中断函数 timer_interrupt()，因此在调用 timer_sleep() 之前都应该保证当前的中断应当被允许，代码中使用断言来保证这一点。中断会在 timer_sleep() 函数开始时被禁止，这样在调用线程调度函数 schedule() 进行上下文切换的时候，其他线程对于 timer_sleep() 会停在对于中断断言的地方。当前线程被挂起、寄存器的值被存储在线程栈上，并且下一个调度的线程状态已经被恢复之后，中断重新被允许，其他线程可以调用 timer_sleep()。

>> A5: How are race conditions avoided when a timer interrupt occurs
>> during a call to timer_sleep()?

理由同A4，此时计时中断被禁止了。

---- RATIONALE ----

>> A6: Why did you choose this design?  In what ways is it superior to
>> another design you considered?

该算法相比于原算法有着显而易见的优点。原算法不断地当前线程放入空闲队列当中，无意义的调用 schedule()，将长时间的占用CPU资源(特别是当前空闲的线程较少时)。而当前算法将线程设置成阻塞状态，在每次时间中断函数中修改并检查线程是否应当被唤醒，CPU将不必进行没有意义的上下文切换，schedule() 的调度将只会涉及处于空闲队列中的线程，而阻塞线程并不在其中。

             PRIORITY SCHEDULING
             ===================

---- DATA STRUCTURES ----

>> B1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.
thread数据结构加入以下成员
   /* 保存在未接受捐赠之前线程的优先级*/
   int init_priority;                 
   /* 保存线程所持有的所有锁 */
   struct list locks;
   /* 当前线程正在等待的锁 */            
   struct lock *lock_waiting;      


lock数据结构加入以下成员
   struct list_elem elem;             /*持有这个锁的所有线程 */
   /*所有持有该锁线程中的最大优先级*/
   int max_priority;


>> B2: Explain the data structure used to track priority donation.
>> Use ASCII art to diagram a nested donation.  (Alternately, submit a
>> .png file.)
为了解决这个问题，我们在thread数据结构中加入init_priority, locks, lock_waiting, 
在lock数据结构中加入elem, max_priority成员来帮助跟踪优先级贡献。

每当一个锁被一个线程所调用时，该线程便插入elem队列中；同样的，每当一个线程释放一个锁，
该线程就从elem队列中移出。

对于每一次优先级捐赠，每当一个锁被调用时，该锁的持有者会进行优先级的检查。如果
持有者的优先级比其他持有该锁线程的优先级低，捐赠就会发生。当前线程的优先级会被捐赠为
和所有持有该锁线程中的最大优先级一样。如果当前线程的优先级比其他线程都要高，则
锁的优先级将改变为和当前线程的优先级一样。

如果该线程又被另外一个线程锁住，那么就会产生一个嵌套。即如果一个线程被多个线程
所捐赠时，维持当前优先级为被捐赠的优先级中的最大值。

当一个锁被释放时，这个锁会从当前线程中的locks队列中移出并检查当前线程是否处于被捐赠的
状态。如果当前locks队列为空，能够知道当前线程不处于被捐赠的状态，那么线程的优先级恢复为
被捐赠前的优先级，即init_priority，否则，取出locks中拥有最大优先级的锁进行比较。如果锁的
优先级比当前优先级还来的大，则改变为当前的最大优先级，否则设置为init_priority。其中locks
队列采用了降序排列，即最大优先级的锁放在对头，因此我们能够保证取出的是线程持有锁的最大
优先级。

使用数据结构和上面的算法，优先级捐赠就能够实现。

举一个例子
A thread, priority 31, has lock lock_1. 
B thread, priority 32, has lock lock_2, and acquire lock_1
C thread, priority 33, acquire lock_2 

Step 1: At the beginning:
=========================
.---------------------------------------------------.
|                Thread A (Beginning)               |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            31 |
| init_priority |                            31 |
| locks             | {lock_1 (max_priority = -1)} |
| lock_waiting   | NULL                          |
'-------------------+-------------------------------'
.---------------------------------------------------.
|                Thread B (Beginning)               |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priority |                            32 |
| locks             | {lock_2 (max_priority = -1)} |
| lock_waiting   | NULL                          |
'-------------------+-------------------------------'
.---------------------------.
|    Thread C (Beginning)   |
+-------------------+-------+
| member            | value |
+-------------------+-------+
| priority          |    33 |
| init_priority |    33 |
| locks             | {}    |
| lock_waiting   | NULL  |
'-------------------+-------'
==================================================================

Step 2: B acquires lock_1:
==========================
.---------------------------------------------------.
|              Thread A (B acquires L1)             |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priority |                            31 |
| locks             | {lock_1 (priority_lock = 32)} |
| lock_waiting   | NULL                          |
'-------------------+-------------------------------'
.---------------------------------------------------.
|              Thread B (B acquires L1)             |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priority |                            32 |
| locks             | {lock_2 (priority_lock = -1)} |
| lock_waiting   | &lock1                        |
'-------------------+-------------------------------'
.---------------------------.
|  Thread C (B acquires L1) |
+-------------------+-------+
| member            | value |
+-------------------+-------+
| priority          |    33 |
| init_priority |    33 |
| locks             | {}    |
| lock_waiting   | NULL  |
'-------------------+-------'
==================================================================

STEP 3-1: C acquires lock_2:
============================
.---------------------------------------------------.
|          Thread B (C acquires L2, Step 1)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            33 |
| init_priority |                            32 |
| locks             | {lock_2 (priority_lock = 33)} |
| lock_waiting   | &lock1                        |
'-------------------+-------------------------------'
.----------------------------------.
| Thread C (C acquires L2, Step 1) |
+----------------------+-----------+
| member               | value     |
+----------------------+-----------+
| priority             |        33 |
| init_priority    |        33 |
| locks                | {}        |
| lock_waiting    | &lock_2   |
'----------------------+-----------'
.---------------------------------------------------.
|          Thread A (C acquires L2, Step 1)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            32 |
| init_priorityl |                            31 |
| locks             | {lock_1 (priority_lock = 32)} |
| lock_waiting   | NULL                          |
'-------------------+-------------------------------'
==================================================================

STEP 3-2: C acquires lock_2:
============================
.---------------------------------------------------.
|          Thread B (C acquires L2, Step 2)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            33 |
| init_priority |                            32 |
| locks             | {lock_2 (priority_lock = 33)} |
| lock_waiting   | &lock1                        |
'-------------------+-------------------------------'
.----------------------------------.
| Thread C (C acquires L2, Step 2) |
+----------------------+-----------+
| member               | value     |
+----------------------+-----------+
| priority             |        33 |
| init_priority    |        33 |
| locks                | {}        |
| lock_waiting     | &lock_2   |
'----------------------+-----------'
.---------------------------------------------------.
|          Thread A (C acquires L2, Step 2)         |
+-------------------+-------------------------------+
| member            | value                         |
+-------------------+-------------------------------+
| priority          |                            33 |
| init_priority |                            31 |
| locks             | {lock_1 (priority_lock = 32)} |
| lock_waiting   | NULL                          |
'-------------------+-------------------------------'
==================================================================

STEP 4: A releases lock_1:
==========================
.-------------------------------.
| Thread A (A releases lock_1)) |
+---------------------+---------+
| member              | value   |
+---------------------+---------+
| priority            |      31 |
| init_priority   |      31 |
| locks               | {}      |
| lock_waiting    | NULL    |
'---------------------+---------'
.----------------------------------------------------.
|            Thread B (A releases lock_1)            |
+-------------------+--------------------------------+
| member            | value                          |
+-------------------+--------------------------------+
| priority          |                             33 |
| init_priority |                             32 |
| locks             | {&lock_2 (priority_lock = 33), |
|                   |  &lock_1 (priority_lock = 32)} |
| lock_waiting   | NULL                           |
'-------------------+--------------------------------'
.------------------------------.
| Thread C (A releases lock_1) |
+--------------------+---------+
| member             | value   |
+--------------------+---------+
| priority           |      33 |
| init_priority  |      33 |
| locks              | {}      |
| lock_waiting   | &lock_2 |
'--------------------+---------'
==================================================================

STEP 5: B releases lock_2:
==========================
.-------------------------------.
| Thread A (B releases lock_2)) |
+---------------------+---------+
| member              | value   |
+---------------------+---------+
| priority            |      31 |
| init_priority  |      31 |
| locks               | {}      |
| lock_waiting   | NULL    |
'---------------------+---------'
.----------------------------------------------------.
|            Thread B (B releases lock_2)            |
+-------------------+--------------------------------+
| member            | value                          |
+-------------------+--------------------------------+
| priority          |                             32 |
| init_priority |                             32 |
| locks             | {&lock_1 (priority_lock = 32)} |
| lock_waiting  | NULL                           |
'-------------------+--------------------------------'
.----------------------------------------------------.
|            Thread C (B releases lock_2)            |
+-------------------+--------------------------------+
| member            | value                          |
+-------------------+--------------------------------+
| priority          |                             33 |
| init_priority |                             33 |
| locks             | {&lock_2 (priority_lock = 33)} |
| lock_waiting   | NULL                           |
'-------------------+--------------------------------'
==================================================================


---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
将等待队列实现为优先队列，按照线程优先级的大小降序排列。


>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
A: 步骤:
   1. 屏蔽中断。
   2. 捐献
     2.1 如果锁的持有者为空
     2.1.1  执行sema_down函数: 如果sema->value的值为0，则将所有请求这个锁的线程放入
	等待队列中，直到sema->value不为0
     2.1.2  将现在的进程设置为锁的持有者
     2.2 比较锁的持有者与当前线程的优先级
     2.2.1  锁持有者的优先级大于当前线程的优先级
     2.2.1.1  当前线程等待锁的释放         
     2.2.1.2  将当前线程设置为锁的持有者
     2.2.2  锁持有者的优先级大于当前线程的优先级
     2.2.2.1  [捐赠] 将锁持有者的优先级设置为当前线程的优先级
     2.2.2.2  等待锁的释放
     2.2.2.3  当前线程成为锁的持有者
   3. 将中断设置为禁用之前的状态。

如果锁的持有者被另一个锁阻塞，就用thread数据结构中的lock_waiting找到那个锁，并
重复上述的操作，直到这个线程的lock_waiting为空，这样，所有的锁持有者就拥有了同样的
优先级。

>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
A: 步骤:
   1. 保证这个线程是当前锁的持有者，如果不是，输出错误。
   2. 屏蔽中断。
   3. 将锁的持有者设置为空
   4. 执行sema_up函数: 如果当前等待队列不为空，则将队列按优先级排序，并取出
		队头。让sema->value加1，这代表当前锁可以被其他队列所
		获取
   5. 设置锁持有者的优先级
     5.1 没有发生捐赠
           将锁持有者的优先级设置为初始优先级
     5.2 发生捐赠
     5.2.1  锁持有者仅仅持有这一个锁
     5.2.1.1  将锁持有者的优先级设置为初始优先级
     5.2.2  嵌套捐赠
     5.2.2.1  将锁持有者的优先级设置为locks队列中的最大优先级

---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?

在优先级捐赠的过程中，锁持有者的优先级可能被它的捐赠者设置，同时，这个线程本身也想要
改变优先级。如果这两个执行的顺序不同，可能会产生不同的结果。

我们不让中断在执行函数时发生。不能够用一个锁防止中断的发生，因为我们没有提供方法让
一个线程和它的捐献者共享一个锁。如果我们对线程加一个锁，锁可能会被禁止使用。

ADVANCED SCHEDULER
==================

---- DATA STRUCTURES ----

>> C1: Copy here the declaration of each new or changed `struct' or
>> `struct' member, global or static variable, `typedef', or
>> enumeration.  Identify the purpose of each in 25 words or less.

struct thread中添加
{
	int nice;               /* Nice parameter. */
	fixed_t recent_cpu;        /* CPU time occupied by the thread. */
}
根据文档内容，给每个线程一个nice参数和一个recent_cpu参数，供后续重新计算线程的优先级以实现mlfqs。

在thread.c中添加变量
fixed_t load_avg;
同样是用于计算优先级的参数。

在fixed_point.h中定义
typedef int fixed_t;


---- ALGORITHMS ----
MLFQS的主要目的是：根据不同CPU区间的特点以区分进程，将占用过多CPU时间的线程的优先级降低，以保证I/O约束和交互线程等占用CPU时间较少的线程的优先级更高，从而减少系统的平均响应时间。

这里我们的BSD Scheduler的主要思路为：每过一定的时间，重新计算线程的优先级，以降低占用过多CPU时间的线程的优先级。具体做法为

1、每过4个ticks( tick % 4 == 0 )，重新计算优先级，公式为
priority  =  max_priority  - (recent_cpu/4) - nice*2
2、每过100个ticks(tick % timer_freq == 0),通过以下公式更新recent_cpu和load_avg
recent_cpu  = recent_cpu * (2*load_avg)/(2*load_avg+1) + nice
load_avg = load_avg*59/60 + 1/60 *  ready_thread
3、每个时钟周期，正在运行的线程的recent_cpu增加1

thread.c中添加以下三个函数：

void
thread_recent_cpu_increase (void)
{
  ASSERT (thread_mlfqs);
  ASSERT (intr_context ());

  struct thread *cur = thread_current ();
  if (cur == idle_thread)
    return;
  cur->recent_cpu = FP_ADD_MIX (cur->recent_cpu, 1);
}

/* refresh load_avg and recent_cpu for all threads. */
void
thread_load_avg_recent_cpu_update (void)
{
  ASSERT (thread_mlfqs);
  ASSERT (intr_context ());

  size_t ready_thread_cnt = list_size (&ready_list);
  if (thread_current () != idle_thread)
    ready_thread_cnt++;

  load_avg = FP_ADD (FP_DIV_MIX (FP_MULT_MIX (load_avg, 59), 60), FP_DIV_MIX (FP_CONST (ready_thread_cnt), 60));

  struct thread *t;
  struct list_elem *e = list_begin (&all_list);

  for (; e != list_end (&all_list); e = list_next(e))
  {
    t = list_entry (e, struct thread, allelem);
    if (t != idle_thread)
    {
      t->recent_cpu = FP_ADD_MIX (FP_MULT (FP_DIV (FP_MULT_MIX (load_avg, 2), FP_ADD_MIX (FP_MULT_MIX (load_avg, 2), 1)), t->recent_cpu), t->nice);
      thread_mlfqs_priority_update (t);
    }
  }
}

/*  */
void
thread_mlfqs_priority_update (struct thread *t)
{
  if (t == idle_thread)
    return;

  ASSERT (thread_mlfqs);
  ASSERT (t != idle_thread);

  t->priority = FP_INT_PART (FP_SUB_MIX (FP_SUB (FP_CONST (PRI_MAX), FP_DIV_MIX (t->recent_cpu, 4)), 2 * t->nice));
  t->priority = t->priority < PRI_MIN ? PRI_MIN : t->priority;
  t->priority = t->priority > PRI_MAX ? PRI_MAX : t->priority;
}

timer.c中的timer_interrupt中加入以下内容
if (thread_mlfqs)
  {
    thread_recent_cpu_increase ();
    if (ticks % TIMER_FREQ == 0)
      thread_load_avg_recent_cpu_update ();
    else if (ticks % 4 == 0)
      thread_mlfqs_priority_update (thread_current ());
  }

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:

由于源代码中给出
#define TIMER_FREQ 100
这里若以TIMER_TREQ=100为例计算，recent_cpu只在最开始计算一次，后续不需要考虑recent_cpu和load_avg通过公式的更新。并且我们这里假设这64个队列均采取FCFS顺序来服务,3个线程在20个时钟周期内都不会结束。


timer  recent_cpu    priority   thread
ticks   A   B   C        A   B   C   to run
-----   --  --  --         --  --  --   ------
 0       0   1   2          63  61 59	 A
 4       4   1   2          62  61 59    A
 8       8   1   2          61  61 59    B
12      8   5   2          61  60 59    A
16     12  5   2          60  60 59    B
20     12  9   2          60  59 59    A
24     16  9   2          59  59  59   C
28     16  9   6          59  59 58    B
32     16  13  6         59  58 58    A
36     20  13  6         58  58 58    C

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?

recent_cpu是不准确的。
可以认为，线程运行时间的一个基本单位是4个时钟周期，因为在线程运行的四个时钟周期中，CPU需要进行调度信息的处理，即recent_cpu和load_avg以及priority的计算，
这就导致一个线程在4个时钟周期中，实际占有CPU的时间是小于4个周期的。
处理方式：粗略认为线程的运行时间为4个时钟周期。

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

如果一个线程实际占有CPU的时间较短，此时，调度信息的处理，即recent_cpu和load_avg以及priority的计算，所占用CPU的时间，就会很大程度上影响此线程的占有CPU
的时间，进而会被降低优先级。
所以如果调度的占用的时间过长，就会导致系统效率的降低。

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?

设计中，没有真正实现64个队列，只是维护了一个readylist的优先队列，通过降低占有CPU时间过长的线程的优先级来控制线程的运行顺序。
这样做实现起来更简便，但线程的调度所需的时间为O(n)，若实现64个队列，则线程的调度所需时间仅为O(1)

>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?

我们在fixed_point.h中定义了一系列的宏来实现浮点数运算。
原因有以下几点：
1、recent_cpu和load_avg的运算需要浮点数运算来实现。
2、比起函数，使用宏定义更加简明。
3、所需功能较为简单，宏定义可以实现。

               SURVEY QUESTIONS
               ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
